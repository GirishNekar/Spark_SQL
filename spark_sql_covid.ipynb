{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Author: Girish <br>\n",
    "@Date: 2024-09-08 <br>\n",
    "@Last Modified by: Girish <br>\n",
    "@Last Modified: 2024-09-08 <br>\n",
    "@Title : Covid Data Analysis <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Death Percentage Globally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, round,when,avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Province/State: string (nullable = true)\n",
      " |-- Country/Region: string (nullable = true)\n",
      " |-- Lat: double (nullable = true)\n",
      " |-- Long: double (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Confirmed: integer (nullable = true)\n",
      " |-- Deaths: integer (nullable = true)\n",
      " |-- Recovered: integer (nullable = true)\n",
      " |-- Active: integer (nullable = true)\n",
      " |-- WHO Region: string (nullable = true)\n",
      "\n",
      "+--------------+---------------+------------+-------------------------+\n",
      "|Country/Region|Total_Confirmed|Total_Deaths|Death_percentage_globally|\n",
      "+--------------+---------------+------------+-------------------------+\n",
      "|          Chad|          64226|        5523|                      8.6|\n",
      "|      Paraguay|         156373|        1663|                     1.06|\n",
      "|        Russia|       45408411|      619385|                     1.36|\n",
      "|         Yemen|          67180|       17707|                    26.36|\n",
      "|       Senegal|         467457|        7177|                     1.54|\n",
      "|    Cabo Verde|          82732|         854|                     1.03|\n",
      "|        Sweden|        4973160|      448913|                     9.03|\n",
      "|        Guyana|          19089|        1346|                     7.05|\n",
      "|       Eritrea|          11786|           0|                      0.0|\n",
      "|   Philippines|        2972611|      110892|                     3.73|\n",
      "|         Burma|          25188|         639|                     2.54|\n",
      "|      Djibouti|         336216|        3011|                      0.9|\n",
      "|      Malaysia|         876874|       12971|                     1.48|\n",
      "|     Singapore|        3502472|        2441|                     0.07|\n",
      "|          Fiji|           2266|           0|                      0.0|\n",
      "|        Turkey|       17903345|      466056|                      2.6|\n",
      "|        Malawi|          89666|        1640|                     1.83|\n",
      "|Western Sahara|            901|          63|                     6.99|\n",
      "|          Iraq|        3093628|      121392|                     3.92|\n",
      "|       Germany|       21059152|      871322|                     4.14|\n",
      "+--------------+---------------+------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder.appName(\"Covid19Analysis\").getOrCreate()\n",
    "\n",
    "file_path = r\"file:///D:\\Apexon_python\\Spark_Practice\\covid_19_clean_complete.csv\"\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "result_df = (\n",
    "    df.groupBy(\"Country/Region\")\n",
    "    .agg(\n",
    "        sum(col(\"Confirmed\").cast(\"int\")).alias(\"Total_Confirmed\"),\n",
    "        sum(col(\"Deaths\").cast(\"int\")).alias(\"Total_Deaths\"),\n",
    "        round(\n",
    "            (sum(col(\"Deaths\").cast(\"int\")) * 100.0) / sum(col(\"Confirmed\").cast(\"int\")),\n",
    "            2\n",
    "        ).alias(\"Death_percentage_globally\")\n",
    "    )\n",
    ")\n",
    "df.printSchema()\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dearh Percentage Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Province/State: string (nullable = true)\n",
      " |-- Country/Region: string (nullable = true)\n",
      " |-- Lat: double (nullable = true)\n",
      " |-- Long: double (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Confirmed: integer (nullable = true)\n",
      " |-- Deaths: integer (nullable = true)\n",
      " |-- Recovered: integer (nullable = true)\n",
      " |-- Active: integer (nullable = true)\n",
      " |-- WHO Region: string (nullable = true)\n",
      "\n",
      "+--------------------+---------------+------------+-----------------------+\n",
      "|      Province/State|Total_Confirmed|Total_Deaths|Death_percentageLocally|\n",
      "+--------------------+---------------+------------+-----------------------+\n",
      "|            Manitoba|          35148|         746|                   2.12|\n",
      "|            Anguilla|            361|           0|                    0.0|\n",
      "|           Guangdong|         268051|        1273|                   0.47|\n",
      "|               Hunan|         178641|         662|                   0.37|\n",
      "|              Shanxi|          30441|           0|                    0.0|\n",
      "|               Tibet|            180|           0|                    0.0|\n",
      "|               Hubei|       11473248|      651932|                   5.68|\n",
      "|               Yukon|           1276|           0|                    0.0|\n",
      "|             Tianjin|          30533|         508|                   1.66|\n",
      "|  Northern Territory|           3537|           0|                    0.0|\n",
      "|             Beijing|         108512|        1383|                   1.27|\n",
      "|Turks and Caicos ...|           2989|         142|                   4.75|\n",
      "|          Montserrat|           1309|          95|                   7.26|\n",
      "|British Virgin Is...|            815|         100|                  12.27|\n",
      "|         Nova Scotia|         110330|        5394|                   4.89|\n",
      "|     South Australia|          54273|         440|                   0.81|\n",
      "|            Victoria|         279524|        2526|                    0.9|\n",
      "|   Western Australia|          70669|        1005|                   1.42|\n",
      "|                null|      803320064|    41984417|                   5.23|\n",
      "|               Macau|           6217|           0|                    0.0|\n",
      "+--------------------+---------------+------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "file_path_india = r\"file:///D:\\Apexon_python\\Spark_Practice\\covid_19_clean_complete.csv\"\n",
    "df = spark.read.csv(file_path_india, header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "result_df_india = (\n",
    "    df.groupBy(\"Province/State\")\n",
    "    .agg(\n",
    "        sum(col(\"Confirmed\").cast(\"int\")).alias(\"Total_Confirmed\"),\n",
    "        sum(col(\"Deaths\").cast(\"int\")).alias(\"Total_Deaths\"),\n",
    "        round(\n",
    "            (sum(col(\"Deaths\").cast(\"int\")) * 100.0) / sum(col(\"Confirmed\").cast(\"int\")),\n",
    "            2\n",
    "        ).alias(\"Death_percentageLocally\")\n",
    "    )\n",
    ")\n",
    "\n",
    "df.printSchema()\n",
    "result_df_india.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infected Polpulation Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- State/UnionTerritory: string (nullable = true)\n",
      " |-- Total_Confirmed: long (nullable = true)\n",
      " |-- Total_Cured: long (nullable = true)\n",
      " |-- locally_Infected: double (nullable = true)\n",
      "\n",
      "+----------------------------------------+---------------+-----------+------------------+\n",
      "|State/UnionTerritory                    |Total_Confirmed|Total_Cured|locally_Infected  |\n",
      "+----------------------------------------+---------------+-----------+------------------+\n",
      "|Nagaland                                |5041742        |4519526    |10.357848537271437|\n",
      "|Karnataka                               |485970693      |441844360  |9.080039935659244 |\n",
      "|Odisha                                  |160130533      |150923455  |5.749732938189865 |\n",
      "|Kerala                                  |458906023      |420174235  |8.440026074793963 |\n",
      "|Ladakh                                  |4054293        |3758960    |7.284451321105806 |\n",
      "|Dadra and Nagar Haveli and Daman and Diu|1938632        |1841750    |4.997441494827285 |\n",
      "|Tamil Nadu                              |431928644      |404095807  |6.443850711600405 |\n",
      "|Telengana                               |69990668       |64666267   |7.607301304796806 |\n",
      "|Chhattisgarh                            |163776262      |151609364  |7.428975268711412 |\n",
      "|Maharashtra***                          |6229596        |6000911    |3.670944311637541 |\n",
      "|Andhra Pradesh                          |392432753      |370426530  |5.607641776016592 |\n",
      "|Lakshadweep                             |915784         |820925     |10.358228577917941|\n",
      "|Madhya Pradesh                          |135625265      |126724997  |6.562396762874528 |\n",
      "|Punjab                                  |99949702       |91458159   |8.495816225645171 |\n",
      "|Manipur                                 |12617943       |11230568   |10.995254931806244|\n",
      "|Daman & Diu                             |2              |0          |100.0             |\n",
      "|Cases being reassigned to states        |345565         |0          |100.0             |\n",
      "|Goa                                     |28240159       |26027201   |7.836209420775575 |\n",
      "|Mizoram                                 |2984732        |2384602    |20.106662842761096|\n",
      "|Bihar****                               |1430909        |1402468    |1.9876176612209377|\n",
      "+----------------------------------------+---------------+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path_india = r\"file:///D:\\Apexon_python\\Spark_Practice\\covid_19_india.csv\"\n",
    "df = spark.read.csv(file_path_india, header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "\n",
    "df = df.withColumn(\"Confirmed\", col(\"Confirmed\").cast(\"int\")) .withColumn(\"Cured\", col(\"Cured\").cast(\"int\"))\n",
    "\n",
    "\n",
    "result_df = (\n",
    "    df\n",
    "    .groupBy(\"State/UnionTerritory\")\n",
    "    .agg(\n",
    "        sum(\"Confirmed\").alias(\"Total_Confirmed\"),\n",
    "        sum(\"Cured\").alias(\"Total_Cured\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"locally_Infected\",\n",
    "        when(col(\"Total_Confirmed\") > 0,\n",
    "             100 - (col(\"Total_Cured\") * 100.0 / col(\"Total_Confirmed\"))\n",
    "        ).otherwise(None)\n",
    "    )\n",
    ")\n",
    "\n",
    "result_df.printSchema()\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infected Population GLobally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Sno: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- State/UnionTerritory: string (nullable = true)\n",
      " |-- ConfirmedIndianNational: string (nullable = true)\n",
      " |-- ConfirmedForeignNational: string (nullable = true)\n",
      " |-- Cured: integer (nullable = true)\n",
      " |-- Deaths: integer (nullable = true)\n",
      " |-- Confirmed: integer (nullable = true)\n",
      "\n",
      "+--------------------+-----------+------------+----------------------------+\n",
      "|State/UnionTerritory|Total_Cases|Total_Active|Globally_Infected_percentage|\n",
      "+--------------------+-----------+------------+----------------------------+\n",
      "|            Nagaland|    5041742|        null|                        null|\n",
      "|           Karnataka|  485970693|       405.0|        8.333835884214524E-5|\n",
      "|              Odisha|  160130533|        23.0|        1.436328198570350...|\n",
      "|              Kerala|  458906023|      1091.0|        2.377393072480986E-4|\n",
      "|              Ladakh|    4054293|       162.0|         0.00399576448964098|\n",
      "|Dadra and Nagar H...|    1938632|        null|                        null|\n",
      "|          Tamil Nadu|  431928644|       138.0|        3.194972176932076...|\n",
      "|           Telengana|   69990668|       246.0|        3.514754281242179...|\n",
      "|        Chhattisgarh|  163776262|        25.0|        1.526472743650725...|\n",
      "|      Maharashtra***|    6229596|        null|                        null|\n",
      "|      Andhra Pradesh|  392432753|        81.0|        2.064047900711284...|\n",
      "|         Lakshadweep|     915784|        null|                        null|\n",
      "|      Madhya Pradesh|  135625265|       105.0|        7.741920356800777E-5|\n",
      "|              Punjab|   99949702|       231.0|        2.311162468498405...|\n",
      "|             Manipur|   12617943|         5.0|        3.962611021463641E-5|\n",
      "|         Daman & Diu|          2|        null|                        null|\n",
      "|Cases being reass...|     345565|        null|                        null|\n",
      "|                 Goa|   28240159|         9.0|        3.186950895000272E-5|\n",
      "|             Mizoram|    2984732|         4.0|        1.340153822855787...|\n",
      "|           Bihar****|    1430909|        null|                        null|\n",
      "+--------------------+-----------+------------+----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Covid19Analysis\").getOrCreate()\n",
    "\n",
    "file_path_india = r\"file:///D:\\Apexon_python\\Spark_Practice\\covid_19_india.csv\"\n",
    "df = spark.read.csv(file_path_india, header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result_df = df.groupBy(\"State/UnionTerritory\") \\\n",
    "    .agg(\n",
    "        sum(\"Confirmed\").alias(\"Total_Cases\"),\n",
    "        sum(\"ConfirmedIndianNational\").alias(\"Total_Active\")\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"Globally_Infected_percentage\",\n",
    "        (col(\"Total_Active\") * 100.0) / col(\"Total_Cases\")\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "df.printSchema()\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Countries with Heighest Infection rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Province/State: string (nullable = true)\n",
      " |-- Country/Region: string (nullable = true)\n",
      " |-- Lat: double (nullable = true)\n",
      " |-- Long: double (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Confirmed: integer (nullable = true)\n",
      " |-- Deaths: integer (nullable = true)\n",
      " |-- Recovered: integer (nullable = true)\n",
      " |-- Active: integer (nullable = true)\n",
      " |-- WHO Region: string (nullable = true)\n",
      "\n",
      "+--------------+---------------+\n",
      "|Country/Region|Total_Confirmed|\n",
      "+--------------+---------------+\n",
      "|            US|      224345948|\n",
      "|        Brazil|       89524967|\n",
      "|        Russia|       45408411|\n",
      "|         India|       40883464|\n",
      "|         Spain|       27404045|\n",
      "|United Kingdom|       26748587|\n",
      "|         Italy|       26745145|\n",
      "|        France|       21210926|\n",
      "|       Germany|       21059152|\n",
      "|          Iran|       19339267|\n",
      "|          Peru|       19263916|\n",
      "|        Turkey|       17903345|\n",
      "|         Chile|       16935654|\n",
      "|        Mexico|       14946202|\n",
      "|         China|       14132002|\n",
      "|      Pakistan|       12833994|\n",
      "|  Saudi Arabia|       12362961|\n",
      "|  South Africa|       11168743|\n",
      "|        Canada|        9356551|\n",
      "|    Bangladesh|        8754729|\n",
      "+--------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path_india = r\"file:///D:\\Apexon_python\\Spark_Practice\\covid_19_clean_complete.csv\"\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result_df = df.withColumn(\"confirmed\", col(\"Confirmed\").cast(\"integer\")) \\\n",
    "    .groupBy(\"Country/Region\") \\\n",
    "    .agg(\n",
    "        sum(\"confirmed\").alias(\"Total_Confirmed\")\n",
    "    ) \\\n",
    "    .orderBy(col(\"Total_Confirmed\").desc())\n",
    "\n",
    "df.printSchema()\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out the countries ans continents witht eh heighest death counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Sno: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- State/UnionTerritory: string (nullable = true)\n",
      " |-- ConfirmedIndianNational: string (nullable = true)\n",
      " |-- ConfirmedForeignNational: string (nullable = true)\n",
      " |-- Cured: integer (nullable = true)\n",
      " |-- Deaths: integer (nullable = true)\n",
      " |-- Confirmed: integer (nullable = true)\n",
      "\n",
      "+--------------------+----------------------+\n",
      "|State/UnionTerritory|Country_highest_Deaths|\n",
      "+--------------------+----------------------+\n",
      "|         Maharashtra|              23737432|\n",
      "|           Karnataka|               6053762|\n",
      "|          Tamil Nadu|               5916658|\n",
      "|               Delhi|               4943294|\n",
      "|       Uttar Pradesh|               4143450|\n",
      "|         West Bengal|               3846989|\n",
      "|      Andhra Pradesh|               2939367|\n",
      "|              Punjab|               2785594|\n",
      "|             Gujarat|               2219448|\n",
      "|        Chhattisgarh|               2063920|\n",
      "|              Kerala|               1888177|\n",
      "|      Madhya Pradesh|               1777752|\n",
      "|             Haryana|               1502799|\n",
      "|           Rajasthan|               1473089|\n",
      "|               Bihar|               1093466|\n",
      "|         Uttarakhand|                986001|\n",
      "|   Jammu and Kashmir|                839694|\n",
      "|              Odisha|                790814|\n",
      "|           Jharkhand|                748641|\n",
      "|               Assam|                638323|\n",
      "+--------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path_india = r\"file:///D:\\Apexon_python\\Spark_Practice\\covid_19_india.csv\"\n",
    "df = spark.read.csv(file_path_india, header=True, inferSchema=True)\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "result_df = (df.groupBy(\"State/UnionTerritory\")  \n",
    "             .agg(sum(\"Deaths\").alias(\"Country_highest_Deaths\"))  \n",
    "             .orderBy(col(\"Country_highest_Deaths\").desc()))  \n",
    "\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Countries with the avg number of deaths by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Province/State: string (nullable = true)\n",
      " |-- Country/Region: string (nullable = true)\n",
      " |-- Lat: double (nullable = true)\n",
      " |-- Long: double (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Confirmed: integer (nullable = true)\n",
      " |-- Deaths: integer (nullable = true)\n",
      " |-- Recovered: integer (nullable = true)\n",
      " |-- Active: integer (nullable = true)\n",
      " |-- WHO Region: string (nullable = true)\n",
      "\n",
      "+--------------+------------------+\n",
      "|Country/Region|  Avg_Daily_Deaths|\n",
      "+--------------+------------------+\n",
      "|            US|58571.335106382976|\n",
      "|United Kingdom|21264.760638297874|\n",
      "|        Brazil|20946.989361702126|\n",
      "|         Italy| 19721.89893617021|\n",
      "|        France|16215.553191489362|\n",
      "|         Spain| 16133.13829787234|\n",
      "|        Mexico| 9192.962765957447|\n",
      "|         India| 5913.994680851064|\n",
      "|          Iran| 5447.531914893617|\n",
      "|       Belgium| 5125.952127659574|\n",
      "|       Germany| 4634.691489361702|\n",
      "|        Canada| 3721.095744680851|\n",
      "|         China|3576.6648936170213|\n",
      "|          Peru| 3468.686170212766|\n",
      "|   Netherlands|  3310.18085106383|\n",
      "|        Russia| 3294.601063829787|\n",
      "|        Turkey| 2479.021276595745|\n",
      "|        Sweden|2387.8351063829787|\n",
      "|       Ecuador| 1843.712765957447|\n",
      "|         Chile|1715.3191489361702|\n",
      "+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "file_path = r\"file:///D:\\Apexon_python\\Spark_Practice\\covid_19_clean_complete.csv\"\n",
    "\n",
    "\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "df.printSchema()\n",
    "\n",
    "daily_deaths_df = (df.groupBy(\"Country/Region\", \"Date\")\n",
    "                   .agg(sum(\"Deaths\").alias(\"Daily_Deaths\")))\n",
    "\n",
    "avg_daily_deaths_df = (daily_deaths_df.groupBy(\"Country/Region\")\n",
    "                       .agg(avg(\"Daily_Deaths\").alias(\"Avg_Daily_Deaths\"))\n",
    "                       .orderBy(col(\"Avg_Daily_Deaths\").desc()))\n",
    "\n",
    "avg_daily_deaths_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continents with Avg number of deaths by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Province/State: string (nullable = true)\n",
      " |-- Country/Region: string (nullable = true)\n",
      " |-- Lat: double (nullable = true)\n",
      " |-- Long: double (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Confirmed: integer (nullable = true)\n",
      " |-- Deaths: integer (nullable = true)\n",
      " |-- Recovered: integer (nullable = true)\n",
      " |-- Active: integer (nullable = true)\n",
      " |-- WHO Region: string (nullable = true)\n",
      "\n",
      "+--------------------+------------------+\n",
      "|           Continent|  Avg_Daily_Deaths|\n",
      "+--------------------+------------------+\n",
      "|            Americas| 102974.9574468085|\n",
      "|              Europe|102505.53191489361|\n",
      "|Eastern Mediterra...|10234.196808510638|\n",
      "|     South-East Asia| 7756.031914893617|\n",
      "|     Western Pacific| 4959.734042553191|\n",
      "|              Africa| 2340.308510638298|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"file:///D:\\Apexon_python\\Spark_Practice\\covid_19_clean_complete.csv\"\n",
    "\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "daily_deaths_by_continent_df = (df.groupBy(\"WHO Region\", \"Date\")\n",
    "                                .agg(sum(\"Deaths\").alias(\"Daily_Deaths\")))\n",
    "\n",
    "avg_daily_deaths_df = (daily_deaths_by_continent_df.groupBy(\"WHO Region\")\n",
    "                       .agg(avg(\"Daily_Deaths\").alias(\"Avg_Daily_Deaths\"))\n",
    "                       .withColumnRenamed(\"WHO Region\", \"Continent\")  # Renaming the column\n",
    "                       .orderBy(col(\"Avg_Daily_Deaths\").desc()))\n",
    "\n",
    "\n",
    "avg_daily_deaths_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average of cases divided by the number of population of each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country/Region: string (nullable = true)\n",
      " |-- Continent: string (nullable = true)\n",
      " |-- Population: integer (nullable = true)\n",
      " |-- TotalCases: integer (nullable = true)\n",
      " |-- NewCases: integer (nullable = true)\n",
      " |-- TotalDeaths: integer (nullable = true)\n",
      " |-- NewDeaths: integer (nullable = true)\n",
      " |-- TotalRecovered: integer (nullable = true)\n",
      " |-- NewRecovered: integer (nullable = true)\n",
      " |-- ActiveCases: integer (nullable = true)\n",
      " |-- Serious,Critical: integer (nullable = true)\n",
      " |-- Tot Cases/1M pop: integer (nullable = true)\n",
      " |-- Deaths/1M pop: double (nullable = true)\n",
      " |-- TotalTests: integer (nullable = true)\n",
      " |-- Tests/1M pop: integer (nullable = true)\n",
      " |-- WHO Region: string (nullable = true)\n",
      "\n",
      "+--------------+------------------------+\n",
      "|Country/Region|Avg_Cases_Per_Population|\n",
      "+--------------+------------------------+\n",
      "|         Qatar|    0.039921575750452756|\n",
      "| French Guiana|    0.027145648579588157|\n",
      "|       Bahrain|     0.02513023907975126|\n",
      "|    San Marino|    0.020596381637102954|\n",
      "|         Chile|    0.019164810228284687|\n",
      "|        Panama|     0.01652703989232825|\n",
      "|        Kuwait|    0.016378443167538764|\n",
      "|          Oman|    0.015769043963734304|\n",
      "|           USA|    0.015193862960518527|\n",
      "|  Vatican City|      0.0149812734082397|\n",
      "+--------------+------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"file:///D:/Apexon_python/Spark_Practice/worldometer_data.csv\"\n",
    "\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "df_with_cases_per_population = df.withColumn(\n",
    "    \"Cases_Per_Population\", \n",
    "    col(\"TotalCases\") * 1.0 / col(\"Population\")\n",
    ")\n",
    "\n",
    "avg_cases_per_population_df = (df_with_cases_per_population.groupBy(\"Country/Region\")\n",
    "                                .agg(avg(\"Cases_Per_Population\").alias(\"Avg_Cases_Per_Population\"))\n",
    "                                .orderBy(col(\"Avg_Cases_Per_Population\").desc()))\n",
    "\n",
    "avg_cases_per_population_df.show(10)\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
